# Aurora

BlindAssist is a mobile application built using Flutter that aims to provide navigation assistance and object detection for visually impaired individuals. The app leverages the power of TensorFlow, Google ML Kit, and Firebase to deliver an accessible and user-friendly experience.

## Features

- **Object Detection**: Utilizing Google ML Kit's object detection capabilities, the app can identify and describe various objects in the user's surroundings, providing crucial information about their environment.
- **Navigation Assistance**: With the integration of Firebase, BlindAssist offers turn-by-turn navigation instructions, helping users navigate through indoor and outdoor spaces safely and efficiently.
- **Voice Commands**: The app supports voice commands, allowing users to interact with the application hands-free.
- **Accessible Design**: The user interface is designed with accessibility in mind, ensuring a seamless experience for visually impaired users.

## Tech Stack

- **Flutter**: The app is built using the Flutter framework, enabling cross-platform development for both iOS and Android devices.
- **TensorFlow Lite**: TensorFlow Lite is used for on-device machine learning models, enabling real-time object detection and classification.
- **Google ML Kit**: Google ML Kit provides pre-trained machine learning models for object detection and other computer vision tasks.
- **Firebase**: Firebase is utilized for backend services such as real-time database, authentication, and cloud functions for navigation assistance.

## Getting Started

To run the BlindAssist app locally, follow these steps:

1. Clone the repository:
